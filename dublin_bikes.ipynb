{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sched, time\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from scipy import optimize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create class to dowload data from url, using an api key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class download_data(object):\n",
    "    \"\"\"\n",
    "    class to download data at periodic time intervals\n",
    "    \"\"\"\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    def __init__(self, url, api_key, delta_t=1800, total_t=1800):\n",
    "        \"\"\"\n",
    "        returns a download object whose attributes are the url of\n",
    "        the website, the api key to download the data, the periodicity\n",
    "        of the download cycle and the total time to perform this task for\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.api_key = api_key\n",
    "        self.delta_t = delta_t\n",
    "        self.total_t = total_t\n",
    "        # initialize a list for downloaded data to be stored in\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        runs download task for specified time period and periodicity\n",
    "        from website with given api key\n",
    "        \"\"\"\n",
    "        \n",
    "        def download():\n",
    "            \"\"\"\n",
    "            function which downloads data from url, url, with api key, api_key\n",
    "            \"\"\"\n",
    "            # set the request parameters\n",
    "            my_url = self.url + '&apiKey=' + self.api_key\n",
    "            user = 'admin'\n",
    "            pwd = 'admin'\n",
    "\n",
    "            # set proper headers\n",
    "            headers = {\"Accept\":\"application/json\"}\n",
    " \n",
    "            # perform the HTTP request\n",
    "            response = requests.get(my_url, auth=(user, pwd), headers=headers)\n",
    " \n",
    "            # append downloaded json data to data_list\n",
    "            self.data_list.append(response.json())\n",
    "            \n",
    "        def comment():\n",
    "            \"\"\"\n",
    "            comment function\n",
    "            \"\"\"\n",
    "            print(time.monotonic(), 'step complete')\n",
    "            \n",
    "        def save_as_csv(filepath):\n",
    "            \"\"\"\n",
    "            saves data as csv file\n",
    "            \"\"\"\n",
    "        \n",
    "        # initialize scheduler\n",
    "        sch = sched.scheduler()\n",
    "        # truncate number of time intervals to integer\n",
    "        time_period = self.delta_t\n",
    "        no_time_intervals = int(self.total_t / self.delta_t) \n",
    "        # execute download at given time periods in total time\n",
    "        time_list = [t * time_period for t in range(no_time_intervals + 1)]\n",
    "        for time_stamp in time_list:\n",
    "            sch.enter(time_stamp, 1, comment)\n",
    "            sch.enter(time_stamp, 2, download)\n",
    "            \n",
    "        # run scheduled tasks\n",
    "        sch.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242027.468 step complete\n",
      "242087.468 step complete\n",
      "242147.468 step complete\n"
     ]
    }
   ],
   "source": [
    "dd = download_data('https://api.jcdecaux.com/vls/v1/stations?contract=Dublin', \n",
    "                     'd2aa5a02f507f8ed4aad52a78772c1496c7cb505', 60*1, 60*1*2)\n",
    "dd.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as outfile:\n",
    "    json.dump(dd.data_list, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as infile:\n",
    "    data = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# displaying the data on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inferring routes via a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bike_list0, bike_list1 = [], []\n",
    "length0, length1 = len(data[0]), len(data[1])\n",
    "\n",
    "# define list of available bikes at each station\n",
    "for n in range(length0):\n",
    "    bike_list0.append(data[0][n]['available_bikes'])\n",
    "for n in range(length1):\n",
    "    bike_list1.append(data[1][n]['available_bikes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define initial and final vectors\n",
    "xf = bike_list1\n",
    "xi = bike_list0\n",
    "# store length of the (two) list(s)\n",
    "n = len(bike_list0)\n",
    "# initialize random probabilties\n",
    "p0 = np.random.rand(n, n)\n",
    "p0_rshp = p0.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_fxn(p_fi):\n",
    "    \"\"\"\n",
    "    gives loss function for given probability matrix,\n",
    "    initial and final vectors\n",
    "    \"\"\"\n",
    "    p_fi_reshaped = p_fi.reshape(n, n)\n",
    "    loss = np.sum((xf - np.dot(xi, p_fi_reshaped))**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun_constr0(p0_rshp_var):\n",
    "    p0_tmp = p0_rshp_var.reshape(n,n)\n",
    "    return np.linalg.norm(1 - np.sum(p0_tmp, axis=0))\n",
    "\n",
    "def fun_constr1(p0_rshp_var):\n",
    "    p0_tmp = p0_rshp_var.reshape(n,n)\n",
    "    return np.linalg.norm(1 - np.sum(p0_tmp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39207093.7633\n"
     ]
    }
   ],
   "source": [
    "cons = ({'type': 'eq', 'fun': fun_constr0}, {'type': 'eq', 'fun': fun_constr1})\n",
    "\n",
    "# test loss function\n",
    "print(loss_fxn(p0_rshp))\n",
    "\n",
    "# define bounds on each entry in the probability matrix\n",
    "bnd = (0, 1)\n",
    "bnd_array = tuple([bnd for n in range(n**2)])\n",
    "\n",
    "# minimize the loss function\n",
    "opt = optimize.minimize(loss_fxn, p0_rshp, method='SLSQP', bounds=bnd_array, constraints=cons)\n",
    "# reshape the data\n",
    "opt_rshp = opt.x.reshape(n, n)\n",
    "print(np.sum(opt_rshp, axis=1), np.sum(opt_rshp, axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what I want to do\n",
    "\n",
    "* put stations on a map\n",
    "* regularly pull data\n",
    "* perform time series analysis\n",
    "* loss function\n",
    "* comparitive study\n",
    "* most frequent route"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
